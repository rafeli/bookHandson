{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import ListedColormap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris[\"data\"][:,[2,3]]\n",
    "y = (iris[\"target\"] == 2).astype(np.float64)\n",
    "\n",
    "# LinearSVC, SVC, SGC offer three equivalent implementations \n",
    "# of linear support vector machine. LinearSVC is fastest. Using SVC (kernel=\"linear\") \n",
    "# is only slower. Using SGD is slower but supports out-of-core training\n",
    "# Detail: (only) LinearSVC \"regularizes bias\" = it tries to minimize offset\n",
    "# which is why a Standardscaler *must* be used. \n",
    "\n",
    "myC = 1        # regularisation\n",
    "m = len(y)\n",
    "svm_clf = Pipeline([\n",
    "  ('scaler', StandardScaler()),\n",
    "   ('lin_svm', LinearSVC(C=myC, loss=\"hinge\"))\n",
    "#   ('lin_svm', SVC(kernel=\"linear\", C=myC))                     # same thing but slower\n",
    "#  ('lin_svm', SGDClassifier(loss=\"hinge\", alpha=1/(m*myC)))     # same, slower convergence\n",
    "])\n",
    "svm_clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a method to plot classifier, use it to plot our first linear svm\n",
    "def plotClassifier(clf, X, y, limits) :\n",
    "    colormapBG = ListedColormap(['#FFDDDD', '#DDFFDD', '#DDDDFF'])\n",
    "    colormapFG = ListedColormap(['#AA0000', '#00AA00', '#0000AA'])\n",
    "    plt.xlim(limits[0],limits[1])\n",
    "    plt.ylim(limits[2], limits[3])\n",
    "    xx, yy = np.meshgrid(np.arange(limits[0], limits[1],0.1), np.arange(limits[2], limits[3],0.1))\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.pcolormesh(xx,yy,Z, cmap=colormapBG)\n",
    "    plt.scatter(X[:,0], X[:,1], c=y, cmap=colormapFG)\n",
    "    \n",
    "plotClassifier(svm_clf, X, y, (0,8,0,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to illustrate non-linear svm we load the \"moons\" dataset\n",
    "X, y = make_moons()\n",
    "X = X + 0.2*np.random.randn(*X.shape)\n",
    "\n",
    "poly_clf = Pipeline([\n",
    "    ('pf', PolynomialFeatures(degree=8)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm', LinearSVC(C=1, loss=\"hinge\"))\n",
    "])\n",
    "\n",
    "poly_clf.fit(X, y)\n",
    "\n",
    "plotClassifier(poly_clf, X, y,(-1.4, 2.5, -1.0, 1.5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
